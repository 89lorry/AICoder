# AICoder - Multi-Agent Code Generation System

A sophisticated multi-agent system that leverages the Model Context Protocol (MCP) to automatically generate complete, tested software applications from natural language descriptions.

## âœ¨ Features

- ğŸ¤– **Four Specialized AI Agents**: Architect, Coder, Tester, and Debugger working in sequence
- ğŸŒ **Dual Interface**: CLI and web-based Gradio UI
- âœ… **Automated Testing**: Generates and runs pytest test cases automatically
- ğŸ› **Smart Debugging**: Automatically fixes failing tests with iterative retry
- ğŸ“Š **API Usage Tracking**: Session-based token consumption monitoring
- âš¡ **Rate Limiting**: Built-in rate limiting for API stability
- ğŸ”„ **Feedback Loop**: Debugger iterates until all tests pass

## ğŸ—ï¸ System Architecture

### Agent Pipeline

```
User Input â†’ Architect â†’ Coder â†’ Tester â†’ [if fail] â†’ Debugger â†’ Output
              â†“           â†“        â†“                      â†“
          Design        Code    Tests                 Fixes
```

**Workflow:**

1. **Agent A: Architect**
   - Analyzes requirements and designs system architecture
   - Creates detailed component specifications
   - Outputs: File structure plan (main.py, utils.py, test_data.py, README.md)

2. **Agent B: Coder**
   - Receives architectural plan from Architect
   - Generates complete, executable code
   - Outputs: All application files with full implementation

3. **Agent C: Tester**
   - Receives code from Coder
   - Generates comprehensive pytest test cases
   - Executes tests and analyzes results
   - Outputs: Test file and execution report

4. **Agent D: Debugger**
   - Activates only if tests fail
   - Analyzes failures and fixes code/tests
   - Retries until tests pass (max 5 attempts)
   - Outputs: Production-ready, tested code

## ğŸ“ Project Structure

```
AICoder/
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ ui.py                      # Gradio web interface
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ mcp_handler.py             # Legacy handler (unused)
â”‚   â””â”€â”€ api_usage_tracker.py       # Session-based token tracking
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agent_architect.py         # Agent A: Architecture design
â”‚   â”œâ”€â”€ agent_coder.py             # Agent B: Code generation
â”‚   â”œâ”€â”€ agent_tester.py            # Agent C: Testing & QA
â”‚   â””â”€â”€ agent_debugger.py          # Agent D: Debugging & fixing
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ local_server.py            # Isolated code execution
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ mcp_client.py              # MCP API client
â”‚   â”œâ”€â”€ file_manager.py            # File operations
â”‚   â”œâ”€â”€ conversation_logger.py     # Agent conversation logging
â”‚   â”œâ”€â”€ memory_manager.py          # Optional LangChain memory
â”‚   â””â”€â”€ langchain_wrapper.py       # LangChain integration
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py                # Configuration management
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ conversations/             # Agent conversation logs
â”œâ”€â”€ workspace/                     # Generated code workspace
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_agents.py
â”‚   â””â”€â”€ test_backend.py
â”œâ”€â”€ workflow_orchestrator.py       # Main workflow controller
â”œâ”€â”€ main.py                        # Application entry point
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ pytest.ini                     # Pytest configuration
â”œâ”€â”€ .env.example                   # Environment template
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸš€ Installation

### 1. Clone the Repository
```bash
git clone https://github.com/89lorry/AICoder.git
cd AICoder
```

### 2. Create Virtual Environment
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Configure Environment
```bash
# Windows
copy .env.example .env

# Linux/Mac
cp .env.example .env

# Edit .env with your MCP API key
```

## âš™ï¸ Configuration

Edit `.env` file:

```env
# Required
MCP_API_KEY=your_api_key_here

# Optional
MCP_ENDPOINT=https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent
WORKSPACE_DIR=./workspace
LOG_LEVEL=INFO
UI_HOST=localhost
UI_PORT=8000
TRACK_API_USAGE=true
ENABLE_MEMORY=false
```

## ğŸ’» Usage

### CLI Mode (Default)

Run the application in command-line mode:

```bash
python main.py
```

The system will:
1. Use predefined requirements (contact management system)
2. Execute the full agent pipeline
3. Display results and API usage in terminal

### Web UI Mode (Recommended)

Launch the Gradio web interface:

```bash
# Local access only
python main.py --ui

# With public sharing link
python main.py --ui --share
```

Then open your browser to `http://localhost:8000`

**UI Features:**
- ğŸ“ Input software description and requirements
- âš¡ Real-time code generation with progress indicator
- ğŸ“‚ Browse generated application and test files
- ğŸ“Š View session API usage (calls and tokens)
- ğŸ¯ Token usage progress bar

## ğŸ“Š API Usage Tracking

The system tracks API usage **per session**:

- **Session-based**: Resets to 0 each time you start the application
- **Real-time**: Updates after each generation
- **Persistent Log**: Saves to `api_usage.json` for history
- **UI Display**: Shows calls and tokens used in current session

Example output:
```
API Calls: 4  |  Total Tokens: 12,543
```

## ğŸ§ª Testing

Run the test suite:

```bash
# Run all tests
pytest

# With coverage report
pytest --cov=. tests/

# Verbose output
pytest -v tests/
```

## ğŸ¯ Example Workflow

### Using Web UI:

1. Start UI: `python main.py --ui`
2. Enter description: "I need a calculator app"
3. Add requirements:
   ```
   - Support +, -, *, / operations
   - Handle division by zero
   - Interactive CLI interface
   ```
4. Click "Generate Code & Tests"
5. View generated files (main.py, utils.py, test_main.py, etc.)
6. Check API usage statistics

### Using CLI:

1. Run: `python main.py`
2. System uses default requirements (contact management)
3. Watch agent pipeline execute
4. View results in terminal
5. Generated code saved to `./workspace/code_project/`

## ğŸ”§ Development

### Architecture Highlights

- **WorkflowOrchestrator**: Coordinates agent pipeline with rate limiting
- **Session Management**: Each agent has unique session ID for logging
- **Rate Limiting**: 6-second delay between API calls (10 RPM limit)
- **Retry Logic**: Debugger attempts up to 5 fixes
- **Isolated Execution**: Code runs in dedicated workspace directories

### Key Components

| Component | Purpose |
|-----------|---------|
| `workflow_orchestrator.py` | Main pipeline controller |
| `agents/agent_*.py` | Specialized AI agents |
| `frontend/ui.py` | Gradio web interface |
| `backend/api_usage_tracker.py` | Token monitoring |
| `server/local_server.py` | Code execution sandbox |
| `utils/mcp_client.py` | MCP API wrapper |

## ğŸ› Troubleshooting

### Port Already in Use

**Windows:**
```cmd
netstat -ano | findstr :8000
taskkill /PID <PID> /F
```

**Linux/Mac:**
```bash
lsof -iTCP:8000 -sTCP:LISTEN -n -P
kill -9 <PID>
```

Or use a different port:
```bash
UI_PORT=7860 python main.py --ui
```

### MCP API Key Not Set

```
âš ï¸  WARNING: MCP_API_KEY not set in environment variables
```

**Solution:**
1. Create `.env` from `.env.example`
2. Add your API key: `MCP_API_KEY=your_key_here`
3. Restart the application

### Tests Failing After Generation

The system automatically handles this:
- Debugger analyzes failures
- Fixes code and/or tests
- Retries up to 5 times
- Reports success or final failure

## ğŸ“ Generated Code Structure

Each generation creates:

```
workspace/code_project/
â”œâ”€â”€ main.py              # Main application logic
â”œâ”€â”€ utils.py             # Helper functions/classes
â”œâ”€â”€ test_data.py         # Sample data for testing
â”œâ”€â”€ README.md            # Project documentation
â””â”€â”€ test_main.py         # Pytest test cases
```

## ğŸ¤ Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“œ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- Built with [Model Context Protocol (MCP)](https://modelcontextprotocol.io/)
- UI powered by [Gradio](https://gradio.app/)
- Testing with [pytest](https://pytest.org/)
- Powered by Google's Gemini 1.5 Flash API

## ğŸ“ Support

For issues, questions, or suggestions:
- Open an issue on GitHub
- Check existing issues for solutions
- Review logs in `./logs/` directory

---

**Made with â¤ï¸ by the AICoder Team**
